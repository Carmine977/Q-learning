{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "BHGE: Keras Refresher.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carmine977/Q-learning/blob/master/BHGE_Keras_Refresher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY29BsdRwUs5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "**VERY IMPORTANT**: if this is your first time using Colab (or Jupyter), you should first visit:\n",
        "\n",
        "- This welcome: https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "- And this overview: https://colab.research.google.com/notebooks/basic_features_overview.ipynb\n",
        "\n",
        "to get a quick overview of working with Google Colaboratory Notebooks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0CDir2xF6ec",
        "colab_type": "text"
      },
      "source": [
        "# First Deep Learning Steps with Keras\n",
        "\n",
        "In this laboratory session we will see how to use Keras/Tensorflow to build, train, interrogate, and evaluate deep models. Remember that Keras/Tensorflow allows us to build **chains** of operations in order to flexibly construct complex and generic **function approximators**. These models are able to **learn** from data by optimizing their parameters to minimize some loss over the traning set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoC_RvQyF6fH",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Load Some Data\n",
        "\n",
        "We will start with our old friend, the Boston Housing Dataset. This time we will load the prepared train/test splits from the Keras library -- using the same splits will help us compare models down the road. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V0aottOVF6fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# Load the Boston Housing dataset splits provided by Keras.\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# Use the sklearn standardization scalar.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Standardize train and test data.\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# What does the data look like (at a high level)?\n",
        "print(f'Train shape: {X_train.shape}')\n",
        "print(f' Test shape: {X_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLvhgpcxF6fN",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1a: Define a Simple Model\n",
        "Now we will build a simple (linear) regression model in Keras. Start by instantiating a `tf.keras.Sequential` model. Then create a single `tf.layers.Dense` layer that takes 13 inputs and produces a **single** scalar output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p52MJuuTGMeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Clear the session.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Your code here.\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1, activation='relu', input_shape=(13,)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac0XKvknGmFQ",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1b: Compile the Model\n",
        "Now use the `compile()` method on the model you defined. Use the `'sgd'` optimizer and the `'mse'` loss. Add the mean average error (`mae`) metric to the list of monitored metrics.\n",
        "\n",
        "**Hint**: you will probably want to spend some time preusing the documentation..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUEqyiEhHCGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model: use Adam optimizer, loss is mean-squared error, monitor mean average error.\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq-UpuTcHEQM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1c: Fit the Model\n",
        "\n",
        "OK, now you're ready to **fit** the model. Use the `model.fit()` method to train the model using the data in `X_train`. Make sure you capture the `history` object returned by `model.fit()` -- you will need it in the following exercises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7SVTPtnI8n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, verbose=1, epochs=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mERZSCfeJGn4",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1d: Monitor Training\n",
        "Look at the `history.history` (I know, terrible design) variable -- **hint**: it's a python `dict`. Use matplotlib to plot the validation and training losses on the same axes to see how training progresses. Do the same for mean average error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0eKsWunJyg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the history of the training and validation losses.\n",
        "plt.plot(history.history['loss'][10:])\n",
        "plt.plot(history.history['val_loss'][10:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yItan55ZF6fP",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: Evaluate the Model\n",
        "OK, now you can finally use the **test** data. Use the `model.evaluate()` method to see how your linear regression works on the test data. Fit a `sklearn.linear_models.LinearRegression` to the training data and see how it compares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWhBhBP4q5uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Fit a LinearRegression model to the training data.\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions from both models.\n",
        "preds_lr = lr.predict(X_test)\n",
        "preds_mlp = model.predict(X_test)\n",
        "\n",
        "# And compare them in terms of mean-squared error.\n",
        "print(f'MLP: {mean_squared_error(y_test, preds_mlp)}')\n",
        "print(f' LR: {mean_squared_error(y_test, preds_lr)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93izEaepF6fR",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3: Fit a Non-linear Model\n",
        "\n",
        "OK, enough with old-school, shallow models. Let's use a more powerful deep model. Define a new model that has **multiple** `Dense` layers before the final output. Decide yourself how *many* layers, and also how *wide* the layers should be. Fit this new model to the training data and see how it performs.\n",
        "\n",
        "**Important**: what *activation* function are you using after your `Dense` layers?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VS1OpkLp8um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear the session.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Make a new model.\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add a hidden layer with 128 units, relu activation\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(13,)))\n",
        "\n",
        "# Output layer with relu activation.\n",
        "model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
        "\n",
        "# Compile the model: use Adam optimizer, loss is mean-squared error, monitor mean average error.\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}